{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata\n",
        "from io import open\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "2Mf9fy5RLOsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klzz5ntHLOsb",
        "outputId": "89bb73d8-80db-4432-d3c2-d094bba5dcc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(\" \"):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "b1mB5C3qLOsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lang = Lang(\"eng\")\n",
        "lang.add_sentence(\"Hi i m Vova and Danik loh and i loh\")\n",
        "print(lang.index2word)\n",
        "print(lang.word2count)\n",
        "print(lang.word2index)\n",
        "print(lang.n_words)\n",
        "print(lang)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'SOS', 1: 'EOS', 2: 'Hi', 3: 'i', 4: 'm', 5: 'Vova', 6: 'and', 7: 'Danik', 8: 'loh'}\n",
            "{'Hi': 1, 'i': 2, 'm': 1, 'Vova': 1, 'and': 2, 'Danik': 1, 'loh': 2}\n",
            "{'Hi': 2, 'i': 3, 'm': 4, 'Vova': 5, 'and': 6, 'Danik': 7, 'loh': 8}\n",
            "9\n",
            "<__main__.Lang object at 0x7f93072373d0>\n"
          ]
        }
      ],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDPGROZ0LOsd",
        "outputId": "1f1f636c-71c4-4599-cbf3-4287d3137438"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "FeovmgvPLOse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_langs(lang1, lang2, reverse=False):\n",
        "    lines = open(f\"{lang1}-{lang2}.txt\", encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
        "    pairs = [[normalize_string(s) for s in l.split(\"\\t\")] for l in lines]\n",
        "\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "wbLAbFpjLOsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filter_pair(pair, reverse=False):\n",
        "    which_pair = 1 if reverse else 0\n",
        "    return len(pair[0].split(\" \")) < MAX_LENGTH and len(pair[1].split(\" \")) < MAX_LENGTH and pair[which_pair].startswith(eng_prefixes)\n",
        "\n",
        "def filter_pairs(pairs, reverse=False):\n",
        "    return [pair for pair in pairs if filter_pair(pair, reverse)]"
      ],
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "iOmEigaZLOsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = read_langs(lang1, lang2, reverse)\n",
        "    print(f\"Read {len(pairs)} sentence pairs\")\n",
        "    pairs = filter_pairs(pairs, reverse)\n",
        "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.add_sentence(pair[0])\n",
        "        output_lang.add_sentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepare_data(\"eng\", \"fra\")\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 2803\n",
            "fra 4345\n",
            "['he s your father .', 'il est ton pere .']\n"
          ]
        }
      ],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aELvzDmwLOsg",
        "outputId": "4c8f279c-b38f-42b6-c841-71f6c81423ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Model**"
      ],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "Hp71sgxmLOsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "\n",
        "        self.embeddings = torch.nn.Embedding(self.input_size, self.hidden_size)\n",
        "        self.gru = torch.nn.GRU(self.hidden_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embeddings(x).view(1, 1, -1)\n",
        "        x, hidden = self.gru(x, hidden)\n",
        "        return x, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.randn(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "cLx_TvTKLOsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderAttention(torch.nn.Module):\n",
        "    def __init__(self, output_size, hidden_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embeddings = torch.nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attention = torch.nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attention_combine = torch.nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = torch.nn.Dropout(self.dropout_p)\n",
        "\n",
        "        self.gru = torch.nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = torch.nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, inp, hidden, encoder_outputs):\n",
        "        embedded = self.embeddings(inp).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attention_weights = self.softmax(\n",
        "            self.attention(torch.cat((embedded[0], hidden[0]), 1))\n",
        "        )\n",
        "        attention_applied = torch.bmm(attention_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attention_applied[0]), 1)\n",
        "        output = self.attention_combine(output).unsqueeze(0)\n",
        "        output = self.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.log_softmax(self.out(output[0]))\n",
        "        return output, hidden, attention_weights"
      ],
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "27Mzt7idLOsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "TPnwjMwXLOsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexes_from_sentences(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
        "\n",
        "def tensor_from_sentences(lang, sentence):\n",
        "    indexes = indexes_from_sentences(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device)\n",
        "\n",
        "def tensor_from_pair(pair):\n",
        "    input_tensor = tensor_from_sentences(input_lang, pair[0])\n",
        "    target_tensor = tensor_from_sentences(output_lang, pair[1])\n",
        "    return input_tensor, target_tensor"
      ],
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "f714DU8nLOsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor, target_tensor = tensor_from_pair(random.choice(pairs))\n",
        "input_tensor, target_tensor"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   2,    3,  147,  577,  532, 1325,  695,    4,    1], device='cuda:0'),\n",
              " tensor([   6,  297,   11,  246, 1085, 1150,  129,  701,    5,    1],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kF2yMYXLOsk",
        "outputId": "099ed9c8-5d79-4a9d-dd62-4d427f16c703"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.6\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optim, decoder_optim, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "    encoder_optim.zero_grad()\n",
        "    decoder_optim.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for idx in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[idx], encoder_hidden)\n",
        "        encoder_outputs[idx] = encoder_output[0, 0]\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing: # With Teacher Forcing\n",
        "        for idx in range(target_length):\n",
        "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[idx].unsqueeze(0))\n",
        "            decoder_input = target_tensor[idx]\n",
        "    else: # Without Teacher Forcing\n",
        "        for idx in range(target_length):\n",
        "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            top_value, top_index = decoder_output.topk(1)\n",
        "            decoder_input = top_index.squeeze().detach()\n",
        "            loss += criterion(decoder_output, target_tensor[idx].unsqueeze(0))\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optim.step()\n",
        "    decoder_optim.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "2Ic2_FrELOsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def as_minutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def time_since(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
      ],
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "-_cE6LfZLOsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_iters(encoder, decoder, n_iters):\n",
        "    start = time.time()\n",
        "\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "\n",
        "    losses = []\n",
        "    total_loss = 0\n",
        "\n",
        "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.0001)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.0001)\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    training_pairs = [tensor_from_pair(random.choice(pairs)) for _ in range(n_iters)]\n",
        "\n",
        "    for idx in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[idx - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        total_loss += loss\n",
        "\n",
        "        if idx % 1000 == 0:\n",
        "            loss_avg = total_loss / 1000\n",
        "            total_loss = 0\n",
        "            losses.append(loss_avg)\n",
        "            t = time_since(start, idx / n_iters)\n",
        "            print(f\"Iter {idx} / {n_iters}\\nLoss {loss_avg}\\nTime {t}\")\n",
        "\n",
        "        plt.plot(losses)"
      ],
      "execution_count": 21,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "K1UmF1LgLOsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensor_from_sentences(input_lang, sentence)\n",
        "        input_size = input_tensor.size(0)\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for idx in range(input_size):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[idx].unsqueeze(0), encoder_hidden)\n",
        "            encoder_outputs[idx] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "        decoder_attentions = torch.zeros(max_length, max_length, device=device)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoded_words = []\n",
        "\n",
        "        for idx in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[idx] = decoder_attention_weights.data\n",
        "            top_value, top_index = decoder_output.topk(1)\n",
        "            if top_index.item() == EOS_token:\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[top_index.item()])\n",
        "            decoder_input = top_index.squeeze().detach()\n",
        "        return decoded_words"
      ],
      "execution_count": 22,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "QKcKfK1gLOsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_randomly(encoder, decoder, n=10):\n",
        "    for idx in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print(f\"Eng: {pair[0]}\")\n",
        "        print(f\"Real\\nFra: {pair[1]}\")\n",
        "        predicted_words = evaluate(encoder, decoder, pair[0])\n",
        "        predicted_sentence = \" \".join(predicted_words)\n",
        "        print(f\"Predicted\\nFra: {predicted_sentence}\")\n",
        "        print(\"-\" * 20)"
      ],
      "execution_count": 23,
      "outputs": [],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "id": "a44Nb20ULOsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_SIZE = 256\n",
        "\n",
        "encoder = Encoder(input_size=input_lang.n_words, hidden_size=HIDDEN_SIZE)\n",
        "decoder = DecoderAttention(output_size=output_lang.n_words, hidden_size=HIDDEN_SIZE)\n",
        "\n",
        "train_iters(encoder, decoder, 100000)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 1000 / 100000\n",
            "Loss 4.13378606093667\n",
            "Time 0m 39s (- 65m 34s)\n",
            "Iter 2000 / 100000\n",
            "Loss 3.6250693106832936\n",
            "Time 1m 8s (- 56m 4s)\n",
            "Iter 3000 / 100000\n",
            "Loss 3.4548688750426\n",
            "Time 1m 38s (- 53m 4s)\n",
            "Iter 4000 / 100000\n",
            "Loss 3.3432625931679256\n",
            "Time 2m 7s (- 51m 4s)\n",
            "Iter 5000 / 100000\n",
            "Loss 3.2162539437029114\n",
            "Time 2m 36s (- 49m 37s)\n",
            "Iter 6000 / 100000\n",
            "Loss 3.10689033128118\n",
            "Time 3m 5s (- 48m 33s)\n",
            "Iter 7000 / 100000\n",
            "Loss 3.0042298087880743\n",
            "Time 3m 34s (- 47m 33s)\n",
            "Iter 8000 / 100000\n",
            "Loss 2.9027468617151704\n",
            "Time 4m 3s (- 46m 42s)\n",
            "Iter 9000 / 100000\n",
            "Loss 2.9276990097806546\n",
            "Time 4m 32s (- 45m 52s)\n",
            "Iter 10000 / 100000\n",
            "Loss 2.8804792576362193\n",
            "Time 5m 1s (- 45m 11s)\n",
            "Iter 11000 / 100000\n",
            "Loss 2.766846822757947\n",
            "Time 5m 30s (- 44m 31s)\n",
            "Iter 12000 / 100000\n",
            "Loss 2.7514127065342553\n",
            "Time 5m 59s (- 43m 55s)\n",
            "Iter 13000 / 100000\n",
            "Loss 2.727052440203938\n",
            "Time 6m 27s (- 43m 14s)\n",
            "Iter 14000 / 100000\n",
            "Loss 2.69588147437005\n",
            "Time 6m 56s (- 42m 38s)\n",
            "Iter 15000 / 100000\n",
            "Loss 2.5995137309125496\n",
            "Time 7m 25s (- 42m 2s)\n",
            "Iter 16000 / 100000\n",
            "Loss 2.5797569892555976\n",
            "Time 7m 53s (- 41m 27s)\n",
            "Iter 17000 / 100000\n",
            "Loss 2.542917481822626\n",
            "Time 8m 22s (- 40m 55s)\n",
            "Iter 18000 / 100000\n",
            "Loss 2.533023107574855\n",
            "Time 8m 51s (- 40m 21s)\n",
            "Iter 19000 / 100000\n",
            "Loss 2.6016587080584603\n",
            "Time 9m 20s (- 39m 50s)\n",
            "Iter 20000 / 100000\n",
            "Loss 2.5053334120863964\n",
            "Time 9m 49s (- 39m 17s)\n",
            "Iter 21000 / 100000\n",
            "Loss 2.4421983920078434\n",
            "Time 10m 17s (- 38m 44s)\n",
            "Iter 22000 / 100000\n",
            "Loss 2.4660215678860267\n",
            "Time 10m 46s (- 38m 12s)\n",
            "Iter 23000 / 100000\n",
            "Loss 2.404551750792966\n",
            "Time 11m 15s (- 37m 40s)\n",
            "Iter 24000 / 100000\n",
            "Loss 2.405193983455974\n",
            "Time 11m 44s (- 37m 11s)\n",
            "Iter 25000 / 100000\n",
            "Loss 2.32691587805171\n",
            "Time 12m 13s (- 36m 40s)\n",
            "Iter 26000 / 100000\n",
            "Loss 2.356041188816609\n",
            "Time 12m 42s (- 36m 9s)\n",
            "Iter 27000 / 100000\n",
            "Loss 2.288222324542672\n",
            "Time 13m 11s (- 35m 38s)\n",
            "Iter 28000 / 100000\n",
            "Loss 2.289422744548607\n",
            "Time 13m 40s (- 35m 8s)\n",
            "Iter 29000 / 100000\n",
            "Loss 2.253241531281811\n",
            "Time 14m 8s (- 34m 38s)\n",
            "Iter 30000 / 100000\n",
            "Loss 2.30854570065765\n",
            "Time 14m 37s (- 34m 8s)\n",
            "Iter 31000 / 100000\n",
            "Loss 2.142875951803298\n",
            "Time 15m 7s (- 33m 40s)\n",
            "Iter 32000 / 100000\n",
            "Loss 2.2411184410030867\n",
            "Time 15m 37s (- 33m 11s)\n",
            "Iter 33000 / 100000\n",
            "Loss 2.2475562206214406\n",
            "Time 16m 7s (- 32m 43s)\n",
            "Iter 34000 / 100000\n",
            "Loss 2.157129119432637\n",
            "Time 16m 36s (- 32m 14s)\n",
            "Iter 35000 / 100000\n",
            "Loss 2.1609628622360635\n",
            "Time 17m 5s (- 31m 45s)\n",
            "Iter 36000 / 100000\n",
            "Loss 2.035535571705632\n",
            "Time 17m 34s (- 31m 15s)\n",
            "Iter 37000 / 100000\n",
            "Loss 2.1153757723342785\n",
            "Time 18m 3s (- 30m 45s)\n",
            "Iter 38000 / 100000\n",
            "Loss 2.063518031046503\n",
            "Time 18m 33s (- 30m 17s)\n",
            "Iter 39000 / 100000\n",
            "Loss 2.1358000227103155\n",
            "Time 19m 3s (- 29m 48s)\n",
            "Iter 40000 / 100000\n",
            "Loss 2.012976986898695\n",
            "Time 19m 32s (- 29m 18s)\n",
            "Iter 41000 / 100000\n",
            "Loss 1.9870781112001052\n",
            "Time 20m 3s (- 28m 51s)\n",
            "Iter 42000 / 100000\n",
            "Loss 1.989664665356325\n",
            "Time 20m 33s (- 28m 22s)\n",
            "Iter 43000 / 100000\n",
            "Loss 2.0000808340152116\n",
            "Time 21m 3s (- 27m 54s)\n",
            "Iter 44000 / 100000\n",
            "Loss 2.03657893537827\n",
            "Time 21m 32s (- 27m 24s)\n",
            "Iter 45000 / 100000\n",
            "Loss 1.9665186246769786\n",
            "Time 22m 0s (- 26m 54s)\n",
            "Iter 46000 / 100000\n",
            "Loss 1.9123346269632138\n",
            "Time 22m 30s (- 26m 24s)\n",
            "Iter 47000 / 100000\n",
            "Loss 1.940266081772626\n",
            "Time 22m 59s (- 25m 55s)\n",
            "Iter 48000 / 100000\n",
            "Loss 1.8649863884442381\n",
            "Time 23m 27s (- 25m 25s)\n",
            "Iter 49000 / 100000\n",
            "Loss 1.910376522048598\n",
            "Time 23m 56s (- 24m 55s)\n",
            "Iter 50000 / 100000\n",
            "Loss 1.8604164442989575\n",
            "Time 24m 25s (- 24m 25s)\n",
            "Iter 51000 / 100000\n",
            "Loss 1.8794635763507044\n",
            "Time 24m 54s (- 23m 55s)\n",
            "Iter 52000 / 100000\n",
            "Loss 1.8645431914225925\n",
            "Time 25m 22s (- 23m 25s)\n",
            "Iter 53000 / 100000\n",
            "Loss 1.774769316770442\n",
            "Time 25m 50s (- 22m 55s)\n",
            "Iter 54000 / 100000\n",
            "Loss 1.806394904077054\n",
            "Time 26m 18s (- 22m 25s)\n",
            "Iter 55000 / 100000\n",
            "Loss 1.8323423535118963\n",
            "Time 26m 47s (- 21m 55s)\n",
            "Iter 56000 / 100000\n",
            "Loss 1.7823533763800832\n",
            "Time 27m 17s (- 21m 26s)\n",
            "Iter 57000 / 100000\n",
            "Loss 1.8032354277632074\n",
            "Time 27m 49s (- 20m 59s)\n",
            "Iter 58000 / 100000\n",
            "Loss 1.7414147030959493\n",
            "Time 28m 18s (- 20m 29s)\n",
            "Iter 59000 / 100000\n",
            "Loss 1.7827301450068989\n",
            "Time 28m 46s (- 20m 0s)\n",
            "Iter 60000 / 100000\n",
            "Loss 1.663776153165813\n",
            "Time 29m 15s (- 19m 30s)\n",
            "Iter 61000 / 100000\n",
            "Loss 1.6891161389281841\n",
            "Time 29m 44s (- 19m 0s)\n",
            "Iter 62000 / 100000\n",
            "Loss 1.7037544535166207\n",
            "Time 30m 13s (- 18m 31s)\n",
            "Iter 63000 / 100000\n",
            "Loss 1.6914597227601296\n",
            "Time 30m 42s (- 18m 2s)\n",
            "Iter 64000 / 100000\n",
            "Loss 1.7373414170997967\n",
            "Time 31m 11s (- 17m 32s)\n",
            "Iter 65000 / 100000\n",
            "Loss 1.6014140295482802\n",
            "Time 31m 41s (- 17m 3s)\n",
            "Iter 66000 / 100000\n",
            "Loss 1.648029462365499\n",
            "Time 32m 11s (- 16m 34s)\n",
            "Iter 67000 / 100000\n",
            "Loss 1.6020695442425323\n",
            "Time 32m 41s (- 16m 5s)\n",
            "Iter 68000 / 100000\n",
            "Loss 1.5674789483573246\n",
            "Time 33m 11s (- 15m 37s)\n",
            "Iter 69000 / 100000\n",
            "Loss 1.6214222057045462\n",
            "Time 33m 40s (- 15m 7s)\n",
            "Iter 70000 / 100000\n",
            "Loss 1.5999654018091312\n",
            "Time 34m 9s (- 14m 38s)\n",
            "Iter 71000 / 100000\n",
            "Loss 1.6038656719561133\n",
            "Time 34m 38s (- 14m 9s)\n",
            "Iter 72000 / 100000\n",
            "Loss 1.5769618175759674\n",
            "Time 35m 8s (- 13m 40s)\n",
            "Iter 73000 / 100000\n",
            "Loss 1.5783884841297335\n",
            "Time 35m 40s (- 13m 11s)\n",
            "Iter 74000 / 100000\n",
            "Loss 1.5775120738728658\n",
            "Time 36m 10s (- 12m 42s)\n",
            "Iter 75000 / 100000\n",
            "Loss 1.534027412989357\n",
            "Time 36m 40s (- 12m 13s)\n",
            "Iter 76000 / 100000\n",
            "Loss 1.5427715901820198\n",
            "Time 37m 10s (- 11m 44s)\n",
            "Iter 77000 / 100000\n",
            "Loss 1.5647661737330836\n",
            "Time 37m 40s (- 11m 15s)\n",
            "Iter 78000 / 100000\n",
            "Loss 1.4940069205060598\n",
            "Time 38m 10s (- 10m 46s)\n",
            "Iter 79000 / 100000\n",
            "Loss 1.4776040336417782\n",
            "Time 38m 40s (- 10m 16s)\n",
            "Iter 80000 / 100000\n",
            "Loss 1.4969301814238942\n",
            "Time 39m 10s (- 9m 47s)\n",
            "Iter 81000 / 100000\n",
            "Loss 1.4775236894826336\n",
            "Time 39m 41s (- 9m 18s)\n",
            "Iter 82000 / 100000\n",
            "Loss 1.4406719824236545\n",
            "Time 40m 11s (- 8m 49s)\n",
            "Iter 83000 / 100000\n",
            "Loss 1.4479392692958544\n",
            "Time 40m 41s (- 8m 19s)\n",
            "Iter 84000 / 100000\n",
            "Loss 1.402034586555971\n",
            "Time 41m 10s (- 7m 50s)\n",
            "Iter 85000 / 100000\n",
            "Loss 1.4474370701424906\n",
            "Time 41m 40s (- 7m 21s)\n",
            "Iter 86000 / 100000\n",
            "Loss 1.4501341159237262\n",
            "Time 42m 10s (- 6m 51s)\n",
            "Iter 87000 / 100000\n",
            "Loss 1.4630906219851174\n",
            "Time 42m 39s (- 6m 22s)\n",
            "Iter 88000 / 100000\n",
            "Loss 1.4138888659009146\n",
            "Time 43m 9s (- 5m 53s)\n",
            "Iter 89000 / 100000\n",
            "Loss 1.3886126401389172\n",
            "Time 43m 38s (- 5m 23s)\n",
            "Iter 90000 / 100000\n",
            "Loss 1.3361905462691248\n",
            "Time 44m 9s (- 4m 54s)\n",
            "Iter 91000 / 100000\n",
            "Loss 1.3922920656700453\n",
            "Time 44m 39s (- 4m 25s)\n",
            "Iter 92000 / 100000\n",
            "Loss 1.4083128273333572\n",
            "Time 45m 11s (- 3m 55s)\n",
            "Iter 93000 / 100000\n",
            "Loss 1.4265295158707196\n",
            "Time 45m 41s (- 3m 26s)\n",
            "Iter 94000 / 100000\n",
            "Loss 1.3343300948644665\n",
            "Time 46m 16s (- 2m 57s)\n",
            "Iter 95000 / 100000\n",
            "Loss 1.3458486180679186\n",
            "Time 46m 46s (- 2m 27s)\n",
            "Iter 96000 / 100000\n",
            "Loss 1.3669172290719453\n",
            "Time 47m 18s (- 1m 58s)\n",
            "Iter 97000 / 100000\n",
            "Loss 1.4199556401087159\n",
            "Time 47m 49s (- 1m 28s)\n",
            "Iter 98000 / 100000\n",
            "Loss 1.3786617210978773\n",
            "Time 48m 20s (- 0m 59s)\n",
            "Iter 99000 / 100000\n",
            "Loss 1.3236591557269053\n",
            "Time 48m 52s (- 0m 29s)\n",
            "Iter 100000 / 100000\n",
            "Loss 1.3629550661484877\n",
            "Time 49m 24s (- 0m 0s)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "datalore": {
          "sheet_delimiter": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7CIqGy0qLOsm",
        "outputId": "3636c13a-891e-4acd-a084-761f42a8063f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(encoder.state_dict(), \"encoder_w.pth\")\n",
        "torch.save(decoder.state_dict(), \"decoder_w.pth\")"
      ],
      "metadata": {
        "id": "nKavlzntMd73"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_randomly(encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5-zlTwGOKBT",
        "outputId": "4203c238-025e-45f6-adde-ce14fe632147"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eng: we are all happy to help .\n",
            "Real\n",
            "Fra: nous sommes toutes contentes d aider .\n",
            "Predicted\n",
            "Fra: nous sommes tous contents d aider .\n",
            "--------------------\n",
            "Eng: she is almost as tall as you .\n",
            "Real\n",
            "Fra: elle est presque aussi grande que toi .\n",
            "Predicted\n",
            "Fra: elle est presque aussi grande que toi .\n",
            "--------------------\n",
            "Eng: he is a member in good standing .\n",
            "Real\n",
            "Fra: c est un membre estime .\n",
            "Predicted\n",
            "Fra: c est un de tennis .\n",
            "--------------------\n",
            "Eng: you re big .\n",
            "Real\n",
            "Fra: vous etes grande .\n",
            "Predicted\n",
            "Fra: vous etes grand .\n",
            "--------------------\n",
            "Eng: i m sure everything will be ok .\n",
            "Real\n",
            "Fra: je suis sur que tout se passera bien .\n",
            "Predicted\n",
            "Fra: je suis sur que tout ira bien .\n",
            "--------------------\n",
            "Eng: i m just beginning .\n",
            "Real\n",
            "Fra: je ne fais que commencer .\n",
            "Predicted\n",
            "Fra: je suis simplement que regarder .\n",
            "--------------------\n",
            "Eng: he is full of new ideas .\n",
            "Real\n",
            "Fra: il est plein de nouvelles idees .\n",
            "Predicted\n",
            "Fra: il est plein de nouveau de . .\n",
            "--------------------\n",
            "Eng: they re staying .\n",
            "Real\n",
            "Fra: elles restent .\n",
            "Predicted\n",
            "Fra: ils sont .\n",
            "--------------------\n",
            "Eng: he is my colleague .\n",
            "Real\n",
            "Fra: il est mon collegue .\n",
            "Predicted\n",
            "Fra: c est mon collegue .\n",
            "--------------------\n",
            "Eng: you re embarrassing me .\n",
            "Real\n",
            "Fra: tu me genes .\n",
            "Predicted\n",
            "Fra: vous me fais .\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Dp0hhlsnOOBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JkEStNFJOJ97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l-1EXu8EOJ7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9FFkReGGOJyT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "text_translation.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}